{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980de2d3",
   "metadata": {},
   "source": [
    "# Homework3\n",
    "顾淳\n",
    "\n",
    "19307110344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a067b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Explore HMM POS Taggers using Brown corpus ---\n",
    "\n",
    "# In this assignment, you will explore two taggers for a Brown corpus.\n",
    "\n",
    "# import your packages here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6acdbf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.probability import ConditionalFreqDist,ConditionalProbDist,FreqDist,LidstoneProbDist,MLEProbDist\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb55db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1. Load and explore your data\n",
    "# 1). load train/test samples from Brown corpus files, brown-train.txt, brown-test.txt.\n",
    "# 2). load all 12 tags from brown-tag.txt and print it out\n",
    "# 3). counting how many sentences and words in both train and test datasets.\n",
    "# 4). for each tag, counting how many words in train and test. e.g, tag1: [count_tr, count_te]\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0171547",
   "metadata": {},
   "source": [
    "## Task 1. Load and explore your data\n",
    "### 1). load train/test samples from Brown corpus files, brown-train.txt, brown-test.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca700aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tag():\n",
    "    return np.loadtxt('brown-tag.txt', skiprows=0, dtype=str)\n",
    "\n",
    "def load_data(train=True):\n",
    "    if train:\n",
    "        path='brown-train.txt'\n",
    "    else:\n",
    "        path='brown-test.txt'\n",
    "    data=[]\n",
    "    sent_count=0\n",
    "    # load txt\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            p = line.strip()\n",
    "            if p == '':\n",
    "                continue\n",
    "            if '\\t' not in p:\n",
    "                sent_name=p\n",
    "                sent_count+=1\n",
    "                continue\n",
    "            data.append(p.split('\\t')+[sent_count-1, sent_name])\n",
    "        data = pd.DataFrame(data,columns=['word', 'tag','sent_index','sent_name'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f222e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=load_data()\n",
    "testset=load_data(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e620b7ae",
   "metadata": {},
   "source": [
    "### 2). load all 12 tags from brown-tag.txt and print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8195ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=load_tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c406c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tags: 12\n",
      "['.' 'ADJ' 'ADP' 'ADV' 'CONJ' 'DET' 'NOUN' 'NUM' 'PRON' 'PRT' 'VERB' 'X']\n"
     ]
    }
   ],
   "source": [
    "print('number of tags:',len(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca97364",
   "metadata": {},
   "source": [
    "### 3). counting how many sentences and words in both train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd01b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences in TRAIN SET: 45799\n",
      "number of words in TRAIN SET: 928327\n",
      "number of sentences in TEST SET: 11539\n",
      "number of words in TEST SET: 232865\n"
     ]
    }
   ],
   "source": [
    "print('number of sentences in TRAIN SET:',trainset.sent_index.max())\n",
    "print('number of words in TRAIN SET:',len(trainset))\n",
    "print('number of sentences in TEST SET:',testset.sent_index.max())\n",
    "print('number of words in TEST SET:',len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ee0a9",
   "metadata": {},
   "source": [
    "### 4). for each tag, counting how many words in train and test. e.g, tag1: [count_tr, count_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8893a163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tag</th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trainset</th>\n",
       "      <td>117723</td>\n",
       "      <td>66985</td>\n",
       "      <td>115752</td>\n",
       "      <td>44765</td>\n",
       "      <td>30455</td>\n",
       "      <td>109418</td>\n",
       "      <td>220451</td>\n",
       "      <td>11921</td>\n",
       "      <td>39657</td>\n",
       "      <td>23889</td>\n",
       "      <td>146199</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testset</th>\n",
       "      <td>29842</td>\n",
       "      <td>16736</td>\n",
       "      <td>29014</td>\n",
       "      <td>11474</td>\n",
       "      <td>7696</td>\n",
       "      <td>27601</td>\n",
       "      <td>55107</td>\n",
       "      <td>2953</td>\n",
       "      <td>9677</td>\n",
       "      <td>5940</td>\n",
       "      <td>36551</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tag            .    ADJ     ADP    ADV   CONJ     DET    NOUN    NUM   PRON  \\\n",
       "trainset  117723  66985  115752  44765  30455  109418  220451  11921  39657   \n",
       "testset    29842  16736   29014  11474   7696   27601   55107   2953   9677   \n",
       "\n",
       "tag         PRT    VERB     X  \n",
       "trainset  23889  146199  1112  \n",
       "testset    5940   36551   274  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_count_trainset=trainset['word'].groupby(trainset['tag']).count()\n",
    "tag_count_testset=testset['word'].groupby(testset['tag']).count()\n",
    "pd.DataFrame([tag_count_trainset,tag_count_testset],index=['trainset','testset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d633df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2. Build a baseline method, namely, the most frequent tagger.\n",
    "#     If you can recall, we introduced a strong baseline method (See Dan's book in Page 163.),\n",
    "#     where we label each word by using the most frequent-used tag associated with it.\n",
    "# 1). find the most frequent class label for each word in the training data.\n",
    "#     For example, {tr_word_1:tag_1,tr_word_2:tag_2,...}\n",
    "# 2). use your built method to predict tags for both train and test datasets.\n",
    "#     You should print out two values: the accuracies of train and test samples.\n",
    "#     You would expect that the accuracy on train will be > 9.0 (but never = 1.0) and higher than on test.\n",
    "\n",
    "# Notice: since there are unkown words in test samples. \n",
    "#  Following ways could handle this (choose one or create your own): \n",
    "#  1). mark all words that appear only once in the data with a \"UNK-x\" tag\n",
    "#  2). tag every out-of-vocabulary word with the majority tag among all training samples.\n",
    "#  3). find more methods in https://github.com/Adamouization/POS-Tagging-and-Unknown-Words\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d266a3b",
   "metadata": {},
   "source": [
    "## Task 2. Build a baseline method, namely, the most frequent tagger.\n",
    "     If you can recall, we introduced a strong baseline method (See Dan's book in Page 163.),\n",
    "     where we label each word by using the most frequent-used tag associated with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bbaa00",
   "metadata": {},
   "source": [
    "### 1). find the most frequent class label for each word in the training data.\n",
    "     For example, {tr_word_1:tag_1,tr_word_2:tag_2,...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d83799",
   "metadata": {},
   "source": [
    "`Get the frequency of each tag of each word`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49b457ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mr.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Podger</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thanked</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>him</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mallory</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Undertaken</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chairmanship</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weigle</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946-52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50490 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              .  ADJ  ADP  ADV  CONJ  DET  NOUN  NUM  PRON  PRT  VERB  X\n",
       "Mr.           0    0    0    0     0    0   696    0     0    0     0  0\n",
       "Podger        0    0    0    0     0    0    19    0     0    0     0  0\n",
       "had           0    0    0    0     0    0     0    0     0    0  4106  1\n",
       "thanked       0    0    0    0     0    0     0    0     0    0     5  0\n",
       "him           0    0    0    0     0    0     0    0  2060    0     0  0\n",
       "...          ..  ...  ...  ...   ...  ...   ...  ...   ...  ...   ... ..\n",
       "Mallory       0    0    0    0     0    0     1    0     0    0     0  0\n",
       "Undertaken    0    0    0    0     0    0     0    0     0    0     1  0\n",
       "chairmanship  0    0    0    0     0    0     1    0     0    0     0  0\n",
       "Weigle        0    0    0    0     0    0     1    0     0    0     0  0\n",
       "1946-52       0    0    0    0     0    0     0    1     0    0     0  0\n",
       "\n",
       "[50490 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique words\n",
    "unque_words=pd.unique(trainset['word'])\n",
    "word_count=pd.DataFrame(np.zeros((len(unque_words), len(tags))),columns=list(tags), index=unque_words)\n",
    "# count frequency\n",
    "for i in range(len(trainset)):\n",
    "    word_count.loc[trainset.iloc[i]['word'],trainset.iloc[i]['tag']]+=1\n",
    "word_count=word_count.astype(int)\n",
    "word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11f113",
   "metadata": {},
   "source": [
    "`Find the most frequency tag of each word`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5f2cab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.             NOUN\n",
       "Podger          NOUN\n",
       "had             VERB\n",
       "thanked         VERB\n",
       "him             PRON\n",
       "                ... \n",
       "Mallory         NOUN\n",
       "Undertaken      VERB\n",
       "chairmanship    NOUN\n",
       "Weigle          NOUN\n",
       "1946-52          NUM\n",
       "Length: 50490, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_most_freq=word_count.apply(pd.Series.idxmax,axis=1)\n",
    "word_count_most_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51568733",
   "metadata": {},
   "source": [
    "### 2). use your built method to predict tags for both train and test datasets.\n",
    "     You should print out two values: the accuracies of train and test samples.\n",
    "     You would expect that the accuracy on train will be > 9.0 (but never = 1.0) and higher than on test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca5972a",
   "metadata": {},
   "source": [
    "`Get the majority tag in train set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e303d50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority tag in trainset is 'NOUN'\n"
     ]
    }
   ],
   "source": [
    "majority_tag=tag_count_trainset.idxmax()\n",
    "print('The majority tag in trainset is \\'%s\\''%majority_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d421cd7",
   "metadata": {},
   "source": [
    "`Label each word by using the most frequent-used tag associated with it.`\n",
    "\n",
    "`Tag every out-of-vocabulary word with the majority tag among all training samples. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfdb0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset['tag_baseline']=trainset['word'].apply(lambda x:word_count_most_freq[x] if x in word_count_most_freq else majority_tag)\n",
    "testset['tag_baseline']=testset['word'].apply(lambda x:word_count_most_freq[x] if x in word_count_most_freq else majority_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86068806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in TRAIN SET: 0.9571961173164197\n",
      "Accuracy in TEST SET: 0.945165653919653\n"
     ]
    }
   ],
   "source": [
    "trainacc_baseline=(trainset['tag']==trainset['tag_baseline']).mean()\n",
    "testacc_baseline=(testset['tag']==testset['tag_baseline']).mean()\n",
    "print('Accuracy in TRAIN SET:',trainacc_baseline)\n",
    "print('Accuracy in TEST SET:',testacc_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e38802c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3. Build an HMM tagger. \n",
    "# 1) You should use nltk.tag.HiddenMarkovModelTagger to build an HMM tagger.\n",
    "#    It has parameters: symbols, states, transitions, outputs, priors, transform (ignore it).\n",
    "#    Specify these parameters properly. For example, you can use MLE to estimate transitions, outputs and priors.\n",
    "#    That is, MLE to estimate matrix A (transition matrix), and matrix B (output probabilites) (See. Page 8.4.3)\n",
    "# 2) After build your model, report both the accuracy of HMM tagger for train samples and test samples.\n",
    "# \n",
    "# 3) Compared with your baseline method, discuss that why your HMM tagger is better/worse than baseline method.\n",
    "\n",
    "# Notice: You may also need to handle unknown words just like Task 2.\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e234c",
   "metadata": {},
   "source": [
    "## Task 3. Build an HMM tagger. \n",
    "### 1) You should use nltk.tag.HiddenMarkovModelTagger to build an HMM tagger.\n",
    "    It has parameters: symbols, states, transitions, outputs, priors, transform (ignore it).\n",
    "    Specify these parameters properly. For example, you can use MLE to estimate transitions, outputs and priors.\n",
    "    That is, MLE to estimate matrix A (transition matrix), and matrix B (output probabilites) (See. Page 8.4.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5abf8dd",
   "metadata": {},
   "source": [
    "`Get the proper format of labeled sequence and test sequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6a7f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset['word,tag']=trainset[['word','tag']].apply(tuple,axis=1)\n",
    "testset['word,tag']=testset[['word','tag']].apply(tuple,axis=1)\n",
    "labeled_seq=trainset['word,tag'].groupby(trainset['sent_index']).agg(tuple).values.tolist()\n",
    "test_seq=testset['word,tag'].groupby(testset['sent_index']).agg(tuple).values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c406fb",
   "metadata": {},
   "source": [
    "`Use this function to build my HMM model.`\n",
    "\n",
    "`I can choose smooth=True/False to control whether to use probability distributions with smoothing.`\n",
    "\n",
    "`With smoothing,we can handle the unseen word in testset properly.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2616b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hmm(smooth=True):\n",
    "    # use LidstoneProbDist if we need smoothing else MLEProbDist\n",
    "    if smooth:\n",
    "        estimator = lambda fdist, bins: LidstoneProbDist(fdist, 0.1, bins)\n",
    "    else:\n",
    "        estimator = lambda fdist, bins: MLEProbDist(fdist)\n",
    "    # get the unique word set\n",
    "    symbols=trainset['word'].unique()\n",
    "    priors = FreqDist()\n",
    "    transitions = ConditionalFreqDist()\n",
    "    outputs = ConditionalFreqDist()\n",
    "    # count the frequency\n",
    "    for sequence in labeled_seq:\n",
    "        last = None\n",
    "        for symbol,state in sequence:\n",
    "            if last is None:\n",
    "                priors[state] += 1\n",
    "            else:\n",
    "                transitions[last][state] += 1\n",
    "            outputs[state][symbol] += 1\n",
    "            last = state\n",
    "\n",
    "    # create probability distributions\n",
    "    priors = estimator(priors,len(tags))\n",
    "    transitions = ConditionalProbDist(transitions, estimator, len(tags))\n",
    "    outputs = ConditionalProbDist(outputs, estimator, len(symbols))\n",
    "    return HiddenMarkovModelTagger(symbols, tags, transitions, outputs, priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f0931",
   "metadata": {},
   "source": [
    "`Build my HMM model with and without smoothing.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84faca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=get_hmm()\n",
    "model2=get_hmm(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd025f",
   "metadata": {},
   "source": [
    "### 2) After build your model, report both the accuracy of HMM tagger for train samples and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "549b736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM with smoothing:\n",
      "TRAINSET accuracy over 928327 tokens: 96.99\n",
      "TESTSET accuracy over 232865 tokens: 95.10\n",
      "\n",
      "HMM without smoothing:\n",
      "TRAINSET accuracy over 928327 tokens: 97.56\n",
      "TESTSET accuracy over 232865 tokens: 75.79\n"
     ]
    }
   ],
   "source": [
    "print('HMM with smoothing:')\n",
    "print('TRAINSET',end=' ')\n",
    "model1.test(labeled_seq)\n",
    "print('TESTSET',end=' ')\n",
    "model1.test(test_seq)\n",
    "print('\\nHMM without smoothing:')\n",
    "print('TRAINSET',end=' ')\n",
    "model2.test(labeled_seq)\n",
    "print('TESTSET',end=' ')\n",
    "model2.test(test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778de87e",
   "metadata": {},
   "source": [
    "### 3) Compared with your baseline method, discuss that why your HMM tagger is better/worse than baseline method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe73432",
   "metadata": {},
   "source": [
    "`We can see that HMM with smoothing is better than baseline both in TRAINSET and TESTSET. That is because HMM with smoothing use more complex model which takes the transition between states and the output probability into consider, and it also can handle a general case while it use smoothing to aviod unseen word.`\n",
    "\n",
    "`HMM without smoothing is much better than baseline in TRAINSET but also much worse than baseline in TESTSET. That maybe results in its' not consider about the unseen words,which cause the overfitting.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
